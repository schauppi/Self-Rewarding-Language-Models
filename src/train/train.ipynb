{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds/anaconda3/envs/srlm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.chdir('/home/ds/workspace/Self-Rewarding-Language-Models')\n",
    "import logging\n",
    "from src.utils.logging.logging_config import setup_logging\n",
    "from src.utils.ModelLoader import ModelLoader\n",
    "from src.utils.ConfigLoader import ConfigLoader\n",
    "from src.utils.create_sft_dataset import create_sft_dataset\n",
    "from src.utils.SFTTrainer import TrainerSFT\n",
    "\n",
    "setup_logging()\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-28 16:53:58,509 - root - INFO - Attempting to load config file at: /home/ds/workspace/Self-Rewarding-Language-Models/config.yaml\n",
      "2024-04-28 16:53:58,513 - root - INFO - Base path set to: /home/ds/workspace/Self-Rewarding-Language-Models/src\n",
      "2024-04-28 16:53:58,515 - root - INFO - Data path set to: /home/ds/workspace/Self-Rewarding-Language-Models/src/data\n",
      "2024-04-28 16:53:58,516 - root - INFO - Model directory path set to: /home/ds/workspace/Self-Rewarding-Language-Models/src/results\n",
      "2024-04-28 16:53:58,517 - root - INFO - Experiment directory set to: /home/ds/workspace/Self-Rewarding-Language-Models/results/results_2024-04-28_16-53-58\n"
     ]
    }
   ],
   "source": [
    "config_loader = ConfigLoader()\n",
    "config = config_loader.config\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config[\"cuda_visible_devices\"]\n",
    "os.environ[\"WANDB_PROJECT\"] = config[\"wandb_project\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-28 17:01:08,125 - root - INFO - Loading BitsAndBytesConfig\n",
      "2024-04-28 17:01:08,128 - root - INFO - Loading Tokenizer\n",
      "2024-04-28 17:01:08,399 - root - INFO - Loading Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-28 17:01:13,193 - root - INFO - Creating PEFT Config\n",
      "trainable params: 23,068,672 || all params: 7,264,800,768 || trainable%: 0.3175403254224521\n",
      "2024-04-28 17:01:13,468 - root - INFO - Loading dataset from: /home/ds/workspace/Self-Rewarding-Language-Models/src/data/ift_short.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds/anaconda3/envs/srlm/lib/python3.11/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/ds/anaconda3/envs/srlm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ds/anaconda3/envs/srlm/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 02:04, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.231600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.322400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.304800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds/anaconda3/envs/srlm/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-662e6584-0c35e4602c5cefaf1ebe7386;059df24c-ad17-4bbe-ae39-83e3e2d98dd8)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted and you are not in the authorized list. Visit https://huggingface.co/mistralai/Mistral-7B-v0.1 to ask for access. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/home/ds/anaconda3/envs/srlm/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loader = ModelLoader(config)\n",
    "model, tokenizer, lora_config = loader.model, loader.tokenizer, loader.lora_config\n",
    "\n",
    "dataset = create_sft_dataset(\n",
    "    dataset_path=(config[\"data_path\"] / config[\"ift_dataset\"]), tokenizer=tokenizer\n",
    ")\n",
    "sft_trainer = TrainerSFT(config=config)\n",
    "sft_adapter_path = sft_trainer.output_dir\n",
    "sft_trainer = sft_trainer.train(\n",
    "    model=model, tokenizer=tokenizer, lora_config=lora_config, dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-28 17:05:31,883 - root - INFO - Loading BitsAndBytesConfig\n",
      "2024-04-28 17:05:31,885 - root - INFO - Loading Tokenizer\n",
      "2024-04-28 17:05:32,321 - root - INFO - Loading Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-28 17:05:37,407 - root - INFO - Loading Lora Weights\n",
      "2024-04-28 17:05:37,456 - root - INFO - Creating PEFT Config\n",
      "trainable params: 23,068,672 || all params: 7,264,800,768 || trainable%: 0.3175403254224521\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loader = ModelLoader(config, adapter=True, adapter_path=sft_adapter_path)\n",
    "model, tokenizer, lora_config = loader.model, loader.tokenizer, loader.lora_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
